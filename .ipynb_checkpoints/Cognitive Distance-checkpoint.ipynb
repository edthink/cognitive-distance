{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cognitive Distance Methods\n",
    "\n",
    "This notebook will accompany the paper 'Towards a Geospatial Model of Cognitive Distance in Urban Spaces: An Objective Measure of Navigibility' by Ed Manley, Gabriele Filomena, and Panos Mavros.\n",
    "\n",
    "The notebook contains the methods used to generate estimates of cognitive distance from conventional GIS data. It also demonstrates the implementation of these methods in estimating cognitive distance in 16 cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import math\n",
    "import requests\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import shape\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "ox.config(log_file=True, log_console=True, use_cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "\n",
    "Each method below simulates the effect of one or more types of cognitive bias in distance perception, as highlighted in the paper. The methods are implemented later in generating estimates for case study cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def landmark_presence(f1, f2):\n",
    "    # if route travelling towards a salient feature then distance to feature is reduced\n",
    "    # use 'tourism' tag - if inline with direction of road, and near to route, the reduce distance by 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elev():\n",
    "\n",
    "    # use API to extract elevation for each node\n",
    "    for _, node in node_geo.iterrows():    \n",
    "        \n",
    "        if 'elev' in node_geo.columns and node_geo.loc[[_], 'elev'].iloc[0] > 0: continue # if elev already extracted then skip\n",
    "        \n",
    "        x, y = node['geometry'].x, node['geometry'].y\n",
    "        r_str = 'https://api.open-elevation.com/api/v1/lookup?locations=%s,%s' % (y, x)  # as of 11.2019, API unreliable\n",
    "        \n",
    "        try:\n",
    "            r = requests.get(r_str)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print ('Request error', e)\n",
    "            continue\n",
    "        \n",
    "        elev = 0\n",
    "        if r.status_code == 200:\n",
    "            elev = int(r.json()['results'][0]['elevation'])\n",
    "        else:\n",
    "            print (r_str)\n",
    "            print (_, 'elevation not found')\n",
    "        \n",
    "        node_geo.loc[[_],  'elev'] = elev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(threshold, pc_inc):\n",
    "    # adjust distance where variation in elevation between u and v\n",
    "    \n",
    "    for _, road in road_geo.iterrows():\n",
    "        \n",
    "        start_elev = node_geo['elev'].loc[[road['u']]].values[0]\n",
    "        end_elev = node_geo['elev'].loc[[road['v']]].values[0]\n",
    "        \n",
    "        slope = ((start_elev - end_elev) / road['length']) * 100\n",
    "      \n",
    "        if slope > threshold or slope < -threshold:\n",
    "            #print (road['name'], slope)\n",
    "            curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "            road_geo.loc[[_],  'new_length'] = curr_distance * pc_inc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Land Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def land_use(buff_dist, pc_inc):\n",
    "    # proximity to shops/activities leads to distraction and distance overestimation\n",
    "    \n",
    "    road_geo_buff = road_geo.copy()\n",
    "    road_geo_buff = road_geo_buff.to_crs({'init': city_epsg})\n",
    "    road_geo_buff['geometry'] = road_geo_buff.apply(buffer, args=[buff_dist], axis=1) # ~25m buffer set up around roads\n",
    "    \n",
    "    for _, road in road_geo_buff.iterrows():\n",
    "        features = 0\n",
    "        features += buildings.loc[buildings['amenity'].notna()].intersects(road['geometry']).values.sum()\n",
    "        \n",
    "        if features >= 3: \n",
    "            curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "            road_geo.loc[[_],  'new_length'] = curr_distance * pc_inc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersections and Turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersections(route):\n",
    "    # get junction-based features of the route\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    p3 = []\n",
    "\n",
    "    minor_junc = 0\n",
    "    medium_junc = 0\n",
    "    major_junc = 0\n",
    "    roundabouts = 0\n",
    "    \n",
    "    turns = 0\n",
    "    sum_deviation = 0\n",
    "        \n",
    "    i = 0\n",
    "    \n",
    "    for _, row in route.iterrows():  \n",
    "                \n",
    "        # counts of roundabouts\n",
    "        if node_geo.loc[[row['v']]].highway.iloc[0] == 'mini_roundabout' or node_geo.loc[[row['v']]].highway.iloc[0] == 'turning_circle':\n",
    "            roundabouts += 1\n",
    "        \n",
    "        # get road grades at junction\n",
    "        if len(route) > i+1: connector = route.iloc[[i+1]] # gets next road\n",
    "        else: i+=1; continue\n",
    "        \n",
    "        if connector.name.iloc[0] != row[8]: # if change in road\n",
    "            if connector['highway'].iloc[0] == 'motorway' or connector['highway'].iloc[0] == 'trunk' or connector['highway'].iloc[0] == 'trunk_link':\n",
    "                major_junc += 1\n",
    "            elif connector['highway'].iloc[0] == 'primary':\n",
    "                medium_junc += 1\n",
    "            elif connector['highway'].iloc[0] == 'secondary':\n",
    "                minor_junc += 1\n",
    "        i+=1  \n",
    "        \n",
    "        # turns and total angular deviation\n",
    "        long = row['geometry'].xy[0][0]\n",
    "        lat = row['geometry'].xy[1][0]\n",
    "        p3 = [long, lat]\n",
    "\n",
    "        if p2 == [] or p1 == p2:\n",
    "            p2 = p3\n",
    "            if p1 == []:\n",
    "                p1 = p2\n",
    "            continue\n",
    "\n",
    "        # Convert the points to numpy latitude/longitude radians space\n",
    "        a = np.radians(np.array(p1))\n",
    "        b = np.radians(np.array(p2))\n",
    "        c = np.radians(np.array(p3))\n",
    "\n",
    "        avec = a - b\n",
    "        cvec = c - b\n",
    "\n",
    "        lat = b[0]\n",
    "        avec[1] *= math.cos(lat)\n",
    "        cvec[1] *= math.cos(lat)\n",
    "\n",
    "        angle2deg = angle_between_vectors_degrees(avec, cvec)\n",
    "        deviation = 180-angle2deg\n",
    "        sum_deviation += deviation\n",
    "\n",
    "        p1 = p2\n",
    "        p2 = p3\n",
    "        \n",
    "        if deviation > 60:\n",
    "            turns +=1\n",
    "            \n",
    "    return minor_junc, medium_junc, major_junc, roundabouts, turns, sum_deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_calcs(route, origin, destination):\n",
    "    # get length-based features of route\n",
    "    length = 0\n",
    "    cog_length = 0\n",
    "    euclid = 0\n",
    "        \n",
    "    # get total length\n",
    "    for _, row in route.iterrows():  \n",
    "        cog_length += row['new_length']\n",
    "        length += row['length']\n",
    "\n",
    "    # get geoms and convert to coordinate system to handle metres easily\n",
    "    o_geom = node_geo.loc[[origin]].geometry\n",
    "    d_geom = node_geo.loc[[destination]].geometry\n",
    "    o_geom = o_geom.to_crs({'init': city_epsg})\n",
    "    d_geom = d_geom.to_crs({'init': city_epsg})\n",
    "    \n",
    "    # get euclidean distance\n",
    "    euclid = o_geom.iloc[0].distance(d_geom.iloc[0])\n",
    "    \n",
    "    return length, cog_length, euclid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_complexity(route):\n",
    "    # sum of nodes within radius of each node on route\n",
    "\n",
    "    sum_node = 0\n",
    "    \n",
    "    for _, row in route.iterrows():  \n",
    "        search_geom = node_geo.loc[[row['v']]].geometry\n",
    "        search_geom = search_geom.to_crs({'init': city_epsg})\n",
    "        search_geom = search_geom.buffer(buffer_dist) # make buffer region at end of segment\n",
    "        sum_node += node_geo.intersects(search_geom.unary_union).values.sum() - 1 # search and sum other nodes (subtract 1 for current node)\n",
    "\n",
    "    if sum_node > 0: return sum_node\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Prominence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prominence(mode):\n",
    "    # relative to travel speed\n",
    "    \n",
    "    for _, road in road_geo.iterrows():\n",
    "        if mode == 'drive':\n",
    "            if road['highway'] == 'motorway' or road['highway'] == 'trunk':\n",
    "                curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "                road_geo.loc[[_],  'new_length'] = curr_distance * 0.7\n",
    "            if road['highway'] == 'primary':\n",
    "                curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "                road_geo.loc[[_],  'new_length'] = curr_distance * 0.8\n",
    "            if road['highway'] == 'secondary':\n",
    "                curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "                road_geo.loc[[_],  'new_length'] = curr_distance * 0.9\n",
    "            if road['highway'] == 'footway' or road['highway'] == 'service':\n",
    "                curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "                road_geo.loc[[_],  'new_length'] = curr_distance * 2.0\n",
    "        elif mode == 'walk':\n",
    "            if road['highway'] == 'footway' or road['highway'] == 'service':\n",
    "                curr_distance = road_geo['new_length'].loc[[_]].values[0]\n",
    "                road_geo.loc[[_],  'new_length'] = curr_distance * 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global City Analysis\n",
    "\n",
    "This section implements the methods for estimating cognitive distance and applies them in 16 cities. This process is divided into four steps:\n",
    "\n",
    "1. Setup parameters for the study - including whether to use elevation data (at the time of writing the Open Elevation API was broken).\n",
    "2. Iterate over the study cities, loading the road network and buildings for the study region and making initial 'road-based' adjustments to the GIS data.\n",
    "3. In `execute_paths`, randomly select origin and destination nodes, and request Euclidean distances, metric path distances, and cognitive distances.\n",
    "4. All path-based calculations are made in `calculate_distance`, where the majority of 'route-based' adjustments are executed. \n",
    "\n",
    "Additional cities can be tested by adding them to the `test_cities.txt` file, maintaining the same format structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_paths = 1000 # number of paths to test per city\n",
    "test_radius = 1000 # radius (in metres) of network from city centroid\n",
    "buffer_dist = 25 # buffer distance (in metres) used for proximity calculations\n",
    "include_elev = False # option to include elevation in calcs\n",
    "travel_mode = 'walk' # 'drive' or 'walk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_file_path = 'input/test_cities.txt' # location of city centroids and EPSG information\n",
    "cities = pd.read_csv(cities_file_path, delimiter='\\t') # load cities data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis on cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York City - Tribeca\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "New York City - Soho\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "New York City - Midtown\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "London - Seven Dials\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "London - Bank\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Paris\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Chicago\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Beijing\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Tokyo\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Sydney\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Madrid\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Rome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TopologyException: Input geom 0 is invalid: Self-intersection at or near point 12.500284167149266 41.889084161621533 at 12.500284167149266 41.889084161621533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Berlin\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Singapore\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Cape Town\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Lima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TopologyException: Input geom 0 is invalid: Self-intersection at or near point -77.029428743431296 -12.044446128433091 at -77.029428743431296 -12.044446128433091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "Mexico City\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "WARNING: No angle between vectors detected\n",
      "La Paz\n",
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n",
      "San Francisco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TopologyException: Input geom 1 is invalid: Self-intersection at or near point -122.41913579454788 37.779471022194173 at -122.41913579454788 37.779471022194173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Making land use adjustments\n",
      "  Adjusting according to road grade\n",
      "  Executing paths\n"
     ]
    }
   ],
   "source": [
    "all_records = []\n",
    "for _, row in cities.iterrows():\n",
    "    \n",
    "    city_epsg = 'epsg:' + str(row['epsg'])\n",
    "    print (row['City'])\n",
    "\n",
    "    # get the road network and buildings for given city at 1000m radius from centre point\n",
    "    try:\n",
    "        road_network = ox.graph_from_point([row['Lat'], row['Lon']], distance = test_radius, network_type=travel_mode, simplify=False, clean_periphery=True)\n",
    "        buildings = ox.footprints.footprints_from_point([row['Lat'], row['Lon']], distance = test_radius, retain_invalid=False)\n",
    "    except:\n",
    "        pass # to ignore TopologyException \n",
    "    \n",
    "    road_network = ox.simplify_graph(road_network)\n",
    "    buildings = buildings.to_crs({'init': city_epsg})\n",
    "    \n",
    "    # extract geography - both nodes and roads\n",
    "    node_geo, road_geo = ox.graph_to_gdfs(road_network, nodes=True, edges=True, fill_edge_geometry=True)\n",
    "    node_geo = node_geo.to_crs({'init': city_epsg})\n",
    "    road_geo = road_geo.to_crs({'init': city_epsg})\n",
    "    road_geo['new_length'] = road_geo['length']\n",
    "    \n",
    "    # apply weights to road segments\n",
    "    if include_elev:\n",
    "        print ('  Extracting elevation')\n",
    "        elev() # calculates elevations of each node using API\n",
    "        print ('  Calculating slope')\n",
    "        slope(5.0, 1.5) # calculates slope and increases distance above threshold\n",
    "    print ('  Making land use adjustments')\n",
    "    land_use(buffer_dist, 1.2) # increases distance where there are intervening opps\n",
    "    print ('  Adjusting according to road grade')\n",
    "    prominence(travel_mode) # adjust length of major roads\n",
    "    \n",
    "    print ('  Executing paths')\n",
    "    city_records = execute_paths(row['City'], city_epsg)\n",
    "    \n",
    "    if len(all_records) == 0: all_records = city_records[:]\n",
    "    else: all_records.extend(city_records)\n",
    "\n",
    "# put all records into a df\n",
    "city_distance_calcs = pd.DataFrame(all_records, columns=['city','euclid','network','cognitive','f_segment','f_isections','f_turns','f_config','f_locations'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origin-destination selection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_paths(this_city, epsg): \n",
    "    \n",
    "    city_records = []\n",
    "    city_count = 0\n",
    "    while city_count < n_paths:\n",
    "\n",
    "        start = road_network.nodes[int(node_geo.sample(1)['osmid'].iloc[0])]\n",
    "        start_nx = start['osmid']\n",
    "        end = road_network.nodes[int(node_geo.sample(1)['osmid'].iloc[0])]\n",
    "        end_nx = end['osmid']\n",
    "\n",
    "        # reproject points to local reference\n",
    "        p1 = Point(start['x'], start['y'])\n",
    "        p2 = Point(end['x'], end['y'])\n",
    "        project = partial(pyproj.transform, \n",
    "            pyproj.Proj(init = 'epsg:4326'), # source coordinate system (WGS84)\n",
    "            pyproj.Proj(init = city_epsg)) # destination coordinate system \n",
    "\n",
    "        start_proj = transform(project, p1)  # apply projection\n",
    "        end_proj = transform(project, p2)  # apply projection\n",
    "        \n",
    "        # calculate distances\n",
    "        euclid_dist = start_proj.distance(end_proj)\n",
    "        cognitive_dist, network_dist, f1, f2, f3, f4, f5 = calculate_distance(start_nx, end_nx)\n",
    "        \n",
    "        if cognitive_dist > -1 and network_dist > -1: # error check\n",
    "            city_records.append([this_city, euclid_dist, network_dist, cognitive_dist, f1, f2, f3, f4, f5])\n",
    "            city_count +=1\n",
    "        \n",
    "        # else: repeat for another OD pair\n",
    "   \n",
    "    return city_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path and distance calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(start_nx, end_nx):\n",
    "    \n",
    "    try:\n",
    "        metric_route = nx.dijkstra_path(road_network, start_nx, end_nx, weight='length')\n",
    "        cognitive_route = nx.dijkstra_path(road_network, start_nx, end_nx, weight='new_length')\n",
    "    except:\n",
    "        print ('   ERROR: Path computation failure')\n",
    "        return -1, -1, -1, -1, -1, -1, -1\n",
    "\n",
    "    # metric length\n",
    "    route_nodes = list(zip(metric_route[:-1], metric_route[1:]))\n",
    "    index = [road_geo[(road_geo['u']==u) & (road_geo['v']==v)].index[0] for u, v in route_nodes]\n",
    "    route_geo = road_geo.loc[index]\n",
    "    metric_length, _, _ = length_calcs(route_geo, start_nx, end_nx) \n",
    "\n",
    "    # cognitive length\n",
    "    route_nodes = list(zip(cognitive_route[:-1], cognitive_route[1:]))\n",
    "    index = [road_geo[(road_geo['u']==u) & (road_geo['v']==v)].index[0] for u, v in route_nodes]\n",
    "    route_geo = road_geo.loc[index]\n",
    "    _, cog_length, euclid = length_calcs(route_geo, start_nx, end_nx)\n",
    "    \n",
    "    f1 = cog_length - metric_length  #  road segment effects\n",
    "    cog_len_prev = cog_length\n",
    "    \n",
    "    # intersections and turns \n",
    "    minor_junc, medium_junc, major_junc, roundabouts, turns, sum_deviation = intersections(route_geo)\n",
    "    \n",
    "    cog_length *= 1 + (minor_junc * 0.01)\n",
    "    cog_length *= 1 + (medium_junc * 0.02)\n",
    "    cog_length *= 1 + ((major_junc + roundabouts) * 0.05)\n",
    "    f2 = cog_length - cog_len_prev  # intersection effect\n",
    "    cog_len_prev = cog_length\n",
    "    \n",
    "    cog_length *= 1 + (turns * 0.1)\n",
    "    f3 = cog_length - cog_len_prev  # turn effect\n",
    "    cog_len_prev = cog_length\n",
    "\n",
    "    # network complexity\n",
    "    sum_nodes = network_complexity(route_geo)\n",
    "    cog_length *= 1 + (sum_nodes * 0.005)\n",
    "    f4 = cog_length - cog_len_prev  # network effect\n",
    "    cog_len_prev = cog_length\n",
    "\n",
    "    # context specific relating to proximity of destination\n",
    "    if euclid < 200: cog_length *= 0.8\n",
    "    elif euclid > 800: cog_length *= 1.2\n",
    "    f5 = cog_length - cog_len_prev  # distribution effect\n",
    "\n",
    "    return cog_length, metric_length, f1, f2, f3, f4, f5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation and Export\n",
    "\n",
    "Some simple methods for summarising and exporting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>euclid</th>\n",
       "      <th>network</th>\n",
       "      <th>cognitive</th>\n",
       "      <th>f_segment</th>\n",
       "      <th>f_isections</th>\n",
       "      <th>f_turns</th>\n",
       "      <th>f_config</th>\n",
       "      <th>f_locations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Beijing</th>\n",
       "      <td>1110.643073</td>\n",
       "      <td>1393.030580</td>\n",
       "      <td>3171.336567</td>\n",
       "      <td>113.919169</td>\n",
       "      <td>21.270002</td>\n",
       "      <td>927.925465</td>\n",
       "      <td>256.800894</td>\n",
       "      <td>458.390457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Berlin</th>\n",
       "      <td>981.354687</td>\n",
       "      <td>1233.137809</td>\n",
       "      <td>5286.730045</td>\n",
       "      <td>154.814946</td>\n",
       "      <td>257.265508</td>\n",
       "      <td>1221.938150</td>\n",
       "      <td>1637.742038</td>\n",
       "      <td>781.831593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cape Town</th>\n",
       "      <td>965.340098</td>\n",
       "      <td>1227.935191</td>\n",
       "      <td>4415.091116</td>\n",
       "      <td>141.206695</td>\n",
       "      <td>82.874160</td>\n",
       "      <td>1110.451006</td>\n",
       "      <td>1209.262172</td>\n",
       "      <td>643.361890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago</th>\n",
       "      <td>1048.307243</td>\n",
       "      <td>1414.640421</td>\n",
       "      <td>3510.787124</td>\n",
       "      <td>177.171798</td>\n",
       "      <td>224.089826</td>\n",
       "      <td>954.606931</td>\n",
       "      <td>218.722526</td>\n",
       "      <td>521.555622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La Paz</th>\n",
       "      <td>1001.254432</td>\n",
       "      <td>1313.905823</td>\n",
       "      <td>3960.232339</td>\n",
       "      <td>184.930422</td>\n",
       "      <td>33.525274</td>\n",
       "      <td>1295.113207</td>\n",
       "      <td>570.192181</td>\n",
       "      <td>562.565433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lima</th>\n",
       "      <td>990.550079</td>\n",
       "      <td>1281.433120</td>\n",
       "      <td>3382.747536</td>\n",
       "      <td>174.947577</td>\n",
       "      <td>74.112896</td>\n",
       "      <td>908.901677</td>\n",
       "      <td>458.090680</td>\n",
       "      <td>485.261586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London - Bank</th>\n",
       "      <td>932.614099</td>\n",
       "      <td>1167.781301</td>\n",
       "      <td>6731.995769</td>\n",
       "      <td>215.425667</td>\n",
       "      <td>69.546406</td>\n",
       "      <td>1802.393519</td>\n",
       "      <td>2498.916278</td>\n",
       "      <td>977.932598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London - Seven Dials</th>\n",
       "      <td>961.685322</td>\n",
       "      <td>1179.951230</td>\n",
       "      <td>5879.430748</td>\n",
       "      <td>258.139653</td>\n",
       "      <td>284.155551</td>\n",
       "      <td>1705.464707</td>\n",
       "      <td>1607.071527</td>\n",
       "      <td>844.648080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madrid</th>\n",
       "      <td>1084.908350</td>\n",
       "      <td>1296.246918</td>\n",
       "      <td>5765.001052</td>\n",
       "      <td>275.190323</td>\n",
       "      <td>71.342006</td>\n",
       "      <td>1714.325736</td>\n",
       "      <td>1532.570971</td>\n",
       "      <td>875.325098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico City</th>\n",
       "      <td>1039.294853</td>\n",
       "      <td>1315.683164</td>\n",
       "      <td>3201.418539</td>\n",
       "      <td>127.932240</td>\n",
       "      <td>329.335181</td>\n",
       "      <td>786.245235</td>\n",
       "      <td>159.741519</td>\n",
       "      <td>482.481201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City - Midtown</th>\n",
       "      <td>1037.885166</td>\n",
       "      <td>1300.903549</td>\n",
       "      <td>2817.178419</td>\n",
       "      <td>177.717794</td>\n",
       "      <td>50.364889</td>\n",
       "      <td>584.441174</td>\n",
       "      <td>289.784650</td>\n",
       "      <td>413.966363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City - Soho</th>\n",
       "      <td>1018.570100</td>\n",
       "      <td>1221.222434</td>\n",
       "      <td>3644.169734</td>\n",
       "      <td>201.228794</td>\n",
       "      <td>54.357966</td>\n",
       "      <td>864.938433</td>\n",
       "      <td>762.159750</td>\n",
       "      <td>540.262356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York City - Tribeca</th>\n",
       "      <td>1005.753112</td>\n",
       "      <td>1213.000861</td>\n",
       "      <td>4019.652379</td>\n",
       "      <td>148.470590</td>\n",
       "      <td>194.484911</td>\n",
       "      <td>1005.258683</td>\n",
       "      <td>861.227962</td>\n",
       "      <td>597.209372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris</th>\n",
       "      <td>1035.101246</td>\n",
       "      <td>1334.076897</td>\n",
       "      <td>4631.337461</td>\n",
       "      <td>159.800704</td>\n",
       "      <td>124.666770</td>\n",
       "      <td>1260.765267</td>\n",
       "      <td>1063.661093</td>\n",
       "      <td>688.366729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rome</th>\n",
       "      <td>949.152219</td>\n",
       "      <td>1157.676093</td>\n",
       "      <td>5680.936339</td>\n",
       "      <td>151.840858</td>\n",
       "      <td>198.450390</td>\n",
       "      <td>1154.841538</td>\n",
       "      <td>2185.302071</td>\n",
       "      <td>832.825389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>San Francisco</th>\n",
       "      <td>1006.973930</td>\n",
       "      <td>1216.293757</td>\n",
       "      <td>4853.776524</td>\n",
       "      <td>229.464563</td>\n",
       "      <td>290.276744</td>\n",
       "      <td>1145.125612</td>\n",
       "      <td>1254.579500</td>\n",
       "      <td>718.036347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>991.240133</td>\n",
       "      <td>1275.918030</td>\n",
       "      <td>4982.953577</td>\n",
       "      <td>191.751054</td>\n",
       "      <td>452.995263</td>\n",
       "      <td>1207.772592</td>\n",
       "      <td>1115.191140</td>\n",
       "      <td>739.325498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sydney</th>\n",
       "      <td>1028.889486</td>\n",
       "      <td>1344.070698</td>\n",
       "      <td>4869.420098</td>\n",
       "      <td>291.615175</td>\n",
       "      <td>243.269088</td>\n",
       "      <td>1350.893349</td>\n",
       "      <td>909.519156</td>\n",
       "      <td>730.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokyo</th>\n",
       "      <td>953.698865</td>\n",
       "      <td>1201.785146</td>\n",
       "      <td>5904.981213</td>\n",
       "      <td>182.842382</td>\n",
       "      <td>117.323263</td>\n",
       "      <td>1249.999792</td>\n",
       "      <td>2308.806555</td>\n",
       "      <td>844.224075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              euclid      network    cognitive   f_segment  \\\n",
       "city                                                                         \n",
       "Beijing                  1110.643073  1393.030580  3171.336567  113.919169   \n",
       "Berlin                    981.354687  1233.137809  5286.730045  154.814946   \n",
       "Cape Town                 965.340098  1227.935191  4415.091116  141.206695   \n",
       "Chicago                  1048.307243  1414.640421  3510.787124  177.171798   \n",
       "La Paz                   1001.254432  1313.905823  3960.232339  184.930422   \n",
       "Lima                      990.550079  1281.433120  3382.747536  174.947577   \n",
       "London - Bank             932.614099  1167.781301  6731.995769  215.425667   \n",
       "London - Seven Dials      961.685322  1179.951230  5879.430748  258.139653   \n",
       "Madrid                   1084.908350  1296.246918  5765.001052  275.190323   \n",
       "Mexico City              1039.294853  1315.683164  3201.418539  127.932240   \n",
       "New York City - Midtown  1037.885166  1300.903549  2817.178419  177.717794   \n",
       "New York City - Soho     1018.570100  1221.222434  3644.169734  201.228794   \n",
       "New York City - Tribeca  1005.753112  1213.000861  4019.652379  148.470590   \n",
       "Paris                    1035.101246  1334.076897  4631.337461  159.800704   \n",
       "Rome                      949.152219  1157.676093  5680.936339  151.840858   \n",
       "San Francisco            1006.973930  1216.293757  4853.776524  229.464563   \n",
       "Singapore                 991.240133  1275.918030  4982.953577  191.751054   \n",
       "Sydney                   1028.889486  1344.070698  4869.420098  291.615175   \n",
       "Tokyo                     953.698865  1201.785146  5904.981213  182.842382   \n",
       "\n",
       "                         f_isections      f_turns     f_config  f_locations  \n",
       "city                                                                         \n",
       "Beijing                    21.270002   927.925465   256.800894   458.390457  \n",
       "Berlin                    257.265508  1221.938150  1637.742038   781.831593  \n",
       "Cape Town                  82.874160  1110.451006  1209.262172   643.361890  \n",
       "Chicago                   224.089826   954.606931   218.722526   521.555622  \n",
       "La Paz                     33.525274  1295.113207   570.192181   562.565433  \n",
       "Lima                       74.112896   908.901677   458.090680   485.261586  \n",
       "London - Bank              69.546406  1802.393519  2498.916278   977.932598  \n",
       "London - Seven Dials      284.155551  1705.464707  1607.071527   844.648080  \n",
       "Madrid                     71.342006  1714.325736  1532.570971   875.325098  \n",
       "Mexico City               329.335181   786.245235   159.741519   482.481201  \n",
       "New York City - Midtown    50.364889   584.441174   289.784650   413.966363  \n",
       "New York City - Soho       54.357966   864.938433   762.159750   540.262356  \n",
       "New York City - Tribeca   194.484911  1005.258683   861.227962   597.209372  \n",
       "Paris                     124.666770  1260.765267  1063.661093   688.366729  \n",
       "Rome                      198.450390  1154.841538  2185.302071   832.825389  \n",
       "San Francisco             290.276744  1145.125612  1254.579500   718.036347  \n",
       "Singapore                 452.995263  1207.772592  1115.191140   739.325498  \n",
       "Sydney                    243.269088  1350.893349   909.519156   730.052632  \n",
       "Tokyo                     117.323263  1249.999792  2308.806555   844.224075  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table = pd.DataFrame()\n",
    "summary_table['euclid'] = city_distance_calcs.groupby('city')['euclid'].mean()\n",
    "summary_table['network'] = city_distance_calcs.groupby('city')['network'].mean()\n",
    "summary_table['cognitive'] = city_distance_calcs.groupby('city')['cognitive'].mean()\n",
    "summary_table['f_segment'] = city_distance_calcs.groupby('city')['f_segment'].mean()\n",
    "summary_table['f_isections'] = city_distance_calcs.groupby('city')['f_isections'].mean()\n",
    "summary_table['f_turns'] = city_distance_calcs.groupby('city')['f_turns'].mean()\n",
    "summary_table['f_config'] = city_distance_calcs.groupby('city')['f_config'].mean()\n",
    "summary_table['f_locations'] = city_distance_calcs.groupby('city')['f_locations'].mean()\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'output/results_n' + str(n_paths) + '_r' + str(test_radius) + '_' + travel_mode + '.csv'\n",
    "summary_table.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buffer(row, value):\n",
    "     return row.geometry.buffer(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_between_vectors_degrees(u, v):\n",
    "    try:\n",
    "        angle = np.degrees(math.acos(np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))))\n",
    "        return angle\n",
    "    except:\n",
    "        print ('   WARNING: No angle between vectors detected')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_features(a,b):\n",
    "    return features.loc[[a]].geometry.centroid.iloc[0].distance(features.loc[[b]].geometry.centroid.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
